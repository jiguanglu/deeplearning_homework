{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy 的基本精神介紹\n",
    "* 數學家發明了一個公式，用來衡量某一群的資料(分佈)所帶資訊量(亂度)\n",
    "* 相信大家看了上句應該還是很抽像，舉例來說如果我們丟躑兩個特製的銅板(A 銅板及B 銅板)，如果其中一個銅板因為物理構造的原因怎麼出現都是正面，而另一個銅板兩面出現的機率接近 50%，用直覺的想法如果我們要預測 A 銅板的丟躑預測結果所花的心思一定小於 B 銅板，更進一步的說法就是 A 銅板丟躑結果分佈所帶的資訊量(entropy)小於 B 銅板\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Entropy 的計算程式範例\n",
    "底下示範計算某個字串的 entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def entropy(ss = 'gargleblaster'):\n",
    "\n",
    "    ssit = {i for i in ss}\n",
    "\n",
    "    n = len(ss)*1.\n",
    "    entropy = 0\n",
    "\n",
    "    for c in ssit:\n",
    "\n",
    "        p_x = ss.count(c)*1./n\n",
    "\n",
    "        if p_x > 0:\n",
    "\n",
    "            entropy += -(p_x)*math.log(p_x,2)\n",
    "\n",
    "#         print(\"{} {} {}\".format(c,ss.count(c),p_x))\n",
    "#     print(ssit)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n0.9182958340544896\n"
     ]
    }
   ],
   "source": [
    "# 丟銅板為例\n",
    "print(entropy(\"111111\"))\n",
    "print(entropy(\"111001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4613201402110088\n"
     ]
    }
   ],
   "source": [
    "# 也可以計算任何字串\n",
    "print(entropy(\"lkejrlejrlewjrlewr\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Cross Entropy\n",
    "* 這一篇文章有一個很直觀的介紹 : http://shuokay.com/2017/06/23/cross-entropy/\n",
    "* Y is real data's label(only two labes. e.q. yes or no )\n",
    "* A is your model prediction result , this result is a probability that your model say this test data's label is \"yes\".\n",
    "* 摘錄這篇文章的重要片段如下\n",
    "<img width=\"70%\" src=\"./imgs/Cross_Entropy.png\" >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.array([1,1,0,0,1])\n",
    "A = np.array([0.8, 0.7, 0.2, 0.1, 0.9])\n",
    "A2 = np.array([0.6, 0.6, 0.2, 0.1, 0.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_entropy(Y, A):\n",
    "    m = len(A)\n",
    "    cost = -(1.0 / m) * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.202736615577\n0.510825623766\n"
     ]
    }
   ],
   "source": [
    "print(cross_entropy(Y,A))\n",
    "print(cross_entropy(Y,A2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
